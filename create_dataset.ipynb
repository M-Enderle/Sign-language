{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             )\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    # Draw right hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "\n",
    "def generate_face(results):\n",
    "\n",
    "    if not results.face_landmarks:\n",
    "        return np.zeros(160)\n",
    "\n",
    "    face = np.array([[res.x, res.y] for res in results.face_landmarks.landmark]) if results.face_landmarks else np.zeros(468*3)\n",
    "    x_min, x_max, y_min, y_max = np.min(face[:,0]), np.max(face[:,0]), np.min(face[:,1]), np.max(face[:,1])\n",
    "    closest_points = []\n",
    "\n",
    "    for y in np.linspace(y_min,y_max,20):\n",
    "        closest_points.append(np.argmin(np.abs(face[:,0] - x_min) + np.abs(face[:,1] - y)))\n",
    "        closest_points.append(np.argmin(np.abs(face[:,0] - x_max) + np.abs(face[:,1] - y)))\n",
    "\n",
    "    for x in np.linspace(x_min,x_max,20):\n",
    "        closest_points.append(np.argmin(np.abs(face[:,0] - x) + np.abs(face[:,1] - y_max)))\n",
    "        closest_points.append(np.argmin(np.abs(face[:,0] - x) + np.abs(face[:,1] - y_min)))\n",
    "\n",
    "    return np.array([[face[i,0], face[i,1]] for i in closest_points]).flatten()\n",
    "\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    lh = np.array([[res.x, res.y] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*2)\n",
    "    rh = np.array([[res.x, res.y] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*2)\n",
    "    return np.concatenate([generate_face(results), lh, rh])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "BACKUP_PATH = os.path.join(\"backup\")\n",
    "DATA_PATH = os.path.join('Data')\n",
    "actions = np.array(['hello', 'world', 'from', 'germany'])\n",
    "no_sequences = 200\n",
    "sequence_length = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "\n",
    "for action in actions:\n",
    "    if not os.path.exists(os.path.join(DATA_PATH, action)):\n",
    "        os.makedirs(os.path.join(DATA_PATH, action))\n",
    "    if not os.path.exists(os.path.join(BACKUP_PATH, action)):\n",
    "        os.makedirs(os.path.join(BACKUP_PATH, action))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "    # NEW LOOP\n",
    "    # Loop through actions\n",
    "    for action in actions:\n",
    "        # Loop through sequences aka videos\n",
    "        while not cv2.waitKey(10) & 0xFF == ord('c'):\n",
    "            ret, frame = cap.read()\n",
    "            image, _ = mediapipe_detection(frame, holistic)\n",
    "\n",
    "            cv2.putText(image, '{}, press c to start'.format(action), (120,200),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 4, cv2.LINE_AA)\n",
    "            cv2.imshow('OpenCV Feed', image)\n",
    "        for sequence in range(no_sequences):\n",
    "            seq = []\n",
    "            # Loop through video length aka sequence length\n",
    "            if sequence != 0 and sequence%40 == 0:\n",
    "                while not cv2.waitKey(10) & 0xFF == ord('c'):\n",
    "                    ret, frame = cap.read()\n",
    "                    image, _ = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                    cv2.putText(image, 'Take a break. press c to continue', (120,200),\n",
    "                                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 4, cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "            while True:\n",
    "\n",
    "                if len(seq) >= sequence_length:\n",
    "                    break\n",
    "\n",
    "                # Read feed\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image, results)\n",
    "\n",
    "                # NEW Apply wait logic\n",
    "                if len(seq) == 0:\n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(1000)\n",
    "                else:\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                # NEW Export keypoints\n",
    "                if results.right_hand_landmarks or results.right_hand_landmarks:\n",
    "                    keypoints = extract_keypoints(results)\n",
    "                    seq.append(keypoints)\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            npy_path = os.path.join(BACKUP_PATH, action, str(sequence))\n",
    "            np.save(npy_path, np.array(seq))\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Only keep neccessary args"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['face']\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "break\n",
    "data_from_to = {\n",
    "    \"face\": (0, 160),\n",
    "    \"lh\": (160, 202),\n",
    "    \"rh\": (202, 244)\n",
    "}\n",
    "\n",
    "\n",
    "def remove_unnec(to_rem: list):\n",
    "    to_rem.sort()\n",
    "    print(to_rem)\n",
    "    for action in actions:\n",
    "        n_seq = len(os.listdir(os.path.join(BACKUP_PATH, action)))\n",
    "        for seq in range(n_seq):\n",
    "            s = []\n",
    "            data = np.load(os.path.join(BACKUP_PATH, action, f\"{seq}.npy\"))\n",
    "            for frame in data:\n",
    "                am_rem = 0\n",
    "                for r in to_rem:\n",
    "                    if r in data_from_to:\n",
    "                        frame = np.delete(frame, [range(data_from_to[r][0]-am_rem, data_from_to[r][1]-am_rem)])\n",
    "                        am_rem += data_from_to[r][1]-data_from_to[r][0]+1\n",
    "                s.append(frame)\n",
    "            npy_path = os.path.join(DATA_PATH, action, str(seq))\n",
    "            np.save(npy_path, np.array(s))\n",
    "\n",
    "\n",
    "\n",
    "remove_unnec([\"face\"])\n",
    "\n",
    "_data = np.load(os.path.join(DATA_PATH, \"learn\", \"0.npy\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "world\n",
      "from\n",
      "germany\n"
     ]
    }
   ],
   "source": [
    "break\n",
    "# Probably temp\n",
    "folders = [\"hello\", \"world\", \"from\", \"germany\"]\n",
    "\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    for file in os.listdir(os.path.join(BACKUP_PATH, folder)):\n",
    "        num = int(str(file).split(\".\")[0]) + 200\n",
    "        old = os.path.join(BACKUP_PATH, folder, str(file))\n",
    "        new = os.path.join(BACKUP_PATH, folder, f\"{num}.npy\")\n",
    "        os.rename(old, new)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}